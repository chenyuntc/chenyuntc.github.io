<!doctype html>
<html lang="en">
    <head>
        <!-- Required meta tags -->
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

        <!-- Bootstrap CSS -->
        <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" 
                               integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
        <title>Volume R-CNN: Unified Framework for CT Object Detection and Instance Segmentation</title>
  <!-- author={Chen, Yun and Chen, Junxuan and Xiao, Bo and Wu, Zhengfang and Chi, Ying and Xie, Xuansong and Hua, Xiansheng}, -->

    </head>
    <body class="container" style="max-width:780px;background-color: #101010;color: #eeeeee;">

        <!-- Title -->
        <div>
            <div class='row mt-5 mb-3'>
                <div class='col text-center'>
                    <p class="h2 font-weight-normal">Volume R-CNN: Unified Framework for CT Object Detection and Instance Segmentation                   </p>
                </div>
            </div>

            <!-- authors -->
            <p class='row text-center h5 font-weight-bold pl-4 pr-4 mb-4' style="align-content: center;text-align: center; align-items: center; font-size:large ;">
                <a class="col-md-3 col-xs-6" href="../../"><span>Yun Chen</span></a>
                <a class="col-md-3 col-xs-6"  ><span>Junxuan Chen</span></a>
                <a class="col-md-3 col-xs-6"  ><span>Bo Xiao</span></a>
                <a class="col-md-3 col-xs-6"  ><span>Zhengfang Wu</span></a>
                <br>
            <!-- </p>
            <p class='row text-center h5 font-weight-bold pl-4 pr-4 mb-4' style="align-content: center;text-align: center; align-items: center; "> -->

            <a class="col-md-3 col-xs-6"  ><span>Ying Chi</span></a>
            <a class="col-md-3 col-xs-6"  ><span>Xuansong Xie</span></a>
            <a class="col-md-3 col-xs-6"  ><span>Xiansheng Hua</span></a>
</p>
            <!-- affiliations -->
            <div class='row mt-1 mt-2' >
                <div class='col text-center'>
                    <p class="h5 font-weight-light">
                     <span>Beijing University of Posts and Telecommunications, &nbsp; Alibaba DAMO Academy</span> 
                    </p>
                </div>
            </div>

  
 

        <!-- Paper section -->
        <div>
            <hr>
            <div class='row'>
                <div class='col-md-3 col-sm-3 col-xs-12 text-center col-sm-3'>
                    <div class="row mt-4">
                        <a href="full.pdf" style="max-width:200px; margin-left:auto; margin-right:auto">
                            <img src="pdf_thumb.png" alt="paper-snapshot" class="img-thumbnail" width="70%" style="box-shadow: 10px 10px 5px grey;">
                        </a>
                    </div>
                    <div class="row mt-4">
                        <div class="col">
                            <a class="h5" href="isbi2019.pdf" style="margin-right:10px">
                                <span>[ISBI Version]</span>
                            </a>
                            <a class="h5" href="full.pdf" target="_blank">
                                <span>[Full Version]</span>
                            </a>
                            <a class="h5" href="bibtex.txt" target="_blank">
                                <span>[BibTeX]</span>
                            </a>
                
                            <!-- <a class="h5" href="http://www.cvlibs.net/datasets/kitti/eval_depth_detail.php?benchmark=depth_completion&result=2882263473c3cd37953f4e40f83f3c5aef84e920" target="_blank">
                                <span>[KITTI]</span>
                            </a> -->
                        </div>
                    </div>
                </div>
                <div class='col-md-9 col-sm-9 col-xs-12'>
                    <p class='h4 font-weight-bold '><b>Abstract</b> </p>
                    <p style='line-height:1;'> 
                            As a fundamental task in computer vision, object detection methods for the 2D image such as Faster R-CNN and SSD can be efficiently trained end-to-end. However, current methods for volumetric data like computed tomography (CT)  usually contain two steps to do region proposal and classification separately. In this work, we present a unified framework called Volume R-CNN for object detection in volumetric data.  Volume R-CNN is an end-to-end method that could perform region proposal, classification and instance segmentation all in one model,  which dramatically reduces computational overhead and parameter numbers. These tasks are joined using a key component named  RoIAlign3D that extracts features of RoIs smoothly and works superiorly well for small objects in the 3D image. To the best of our knowledge, Volume R-CNN is the first common end-to-end framework for both object detection and instance segmentation in CT. Without bells and whistles, our single model achieves remarkable results in LUNA16. Ablation experiments are conducted to analyze the effectiveness of our method.

                    </p>
                    <!-- <p><strong style="color:red;">1st place on KITTI Depth Completion</strong></p> -->
                </div>
            </div>
        </div>
        <br><br>


        <!-- Method Overview -->
        <!-- <h4 align="center"><b>Method Overview</b> </h4>
        <br>
        <div style="text-align: center;">
			<img src="fusenet.svg" width="600">
		</div>
<br> 
        <p>  The proposed <i>2D-3D Fuse Block</i>  can fully exploit both 2D appearance and 3D geometric features. It contains 3 components:</p>

        <li><b>2D Branch</b> : exctract multi-scale 2D convolution on RGBD feature map.</li>
        <li><b>3D Branch</b>: index point features from the image with projection matrix and then adopt continuous convoluton to extract 3D geometric features.</li>
        <li><b>Fusion</b>: fuse the point features back to image plane using unprojection and sum all features.</li>
        <br>
        <p>      FuseNet is built with proposed blocks plus a few 2D convolution layers at the input and output stages. It is trained from scratch without using any additional data or pretrain    weight.</p>
  
        <br><br> -->

        <div id="footer">
            <div class="container text-center">
              <div class="fnav">
                <p style="font-size: medium;">Copyleft &#127279; 2020 Yun Chen. Happy ^_^ Coding. &nbsp </p>
              </div>
            </div>
          </div>
        <!-- Optional JavaScript -->
        <!-- jQuery first, then Popper.js, then Bootstrap JS -->
        <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" 
                integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" 
                integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
        <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" 
                integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>
    </body>
</html>
