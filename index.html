<!DOCTYPE html>
<!-- This site was created with Hugo Blox. https://hugoblox.com -->
<!-- Last Published: December 15, 2024 --><html lang="en-us" >


<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  
  
    <meta name="generator" content="Hugo Blox Builder 5.9.7" />
  

  
  












  
  










  







  
  
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  

  
  
  
    
      
      <link rel="preload" as="style" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap">
      <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media="print" onload="this.media='all'">
    
  

  
  

  
  

  

  <link rel="stylesheet" href="/css/vendor-bundle.min.e4b9d3e8ce28da563d74b4089f677743.css" media="print" onload="this.media='all'">

  
  
  
    
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1.9.4/css/academicons.min.css" integrity="sha512-IW0nhlW5MgNydsXJO40En2EoCkTTjZhI3yuODrZIc8cQ4h1XcF53PsqDHa09NqnkXuIe0Oiyyj171BqZFwISBw==" crossorigin="anonymous" media="print" onload="this.media='all'">
    

    
    
    
    
      
      
      
      
        
      
        
      
        
      
        
      
        
      
    
    
    

    
    
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.css" integrity="" crossorigin="anonymous" media="print" onload="this.media='all'">
    

    

    
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      
        
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
  

  
  
  
  
  
  
  <link rel="stylesheet" href="/css/wowchemy.f6689966c0a10712f95f034011917db0.css" />

  
  
  

  
  
  
  
  
  
  
    
    
    <link rel="stylesheet" href="/css/libs/chroma/github-light.min.css" title="hl-light" media="print" onload="this.media='all'" >
    <link rel="stylesheet" href="/css/libs/chroma/dracula.min.css" title="hl-dark" media="print" onload="this.media='all'" disabled>
  

  
  



























  
  
  






  <meta name="author" content="Yun Chen" />





  

<meta name="description" content="Researcher/PhD student" />



<link rel="alternate" hreflang="en-us" href="https://tmux.top/" />
<link rel="canonical" href="https://tmux.top/" />



  <link rel="manifest" href="/manifest.webmanifest" />



<link rel="icon" type="image/png" href="/media/icon_hu7168323951238697375.png" />
<link rel="apple-touch-icon" type="image/png" href="/media/icon_hu8479497048083762863.png" />

<meta name="theme-color" content="#1565c0" />










  
  






<meta property="twitter:card" content="summary" />
<meta property="twitter:image" content="https://tmux.top/media/icon_hu9443299162589431023.png" />



  
    
    
    
  

<meta property="og:type" content="profile" />
<meta property="og:site_name" content="Yun Chen" />
<meta property="og:url" content="https://tmux.top/" />
<meta property="og:title" content="Yun Chen" />
<meta property="og:description" content="Researcher/PhD student" /><meta property="og:image" content="https://tmux.top/media/icon_hu9443299162589431023.png" /><meta property="og:locale" content="en-us" />

  
    <meta property="og:updated_time" content="2024-10-01T00:00:00&#43;00:00" />
  





<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "WebSite",
  "potentialAction": {
    "@type": "SearchAction",
    "target": "https://tmux.top/?q={search_term_string}",
    "query-input": "required name=search_term_string"
  },
  "url": "https://tmux.top/"
}
</script>


  




  
  
  

  
  
    <link rel="alternate" href="/index.xml" type="application/rss+xml" title="Yun Chen" />
  

  


  
  <title>Yun Chen</title>

  
  
  
  











</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#navbar-main" class="page-wrapper   "  >

  
  
  
  
  
  
  
  
  
  <script src="/js/wowchemy-init.min.9e4214442a7711d35691acd58f6f6361.js"></script>

  


<aside class="search-modal" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#" aria-label="Close"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search" class="form-control"
        aria-label="Search...">
        
      </div>

      
      

      

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>



  <div class="page-header header--fixed">
  
  
  
  
  












<header>
  <nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
    <div class="container-xl">

      
      <div class="d-none d-lg-inline-flex">
        <a class="navbar-brand" href="/">Yun Chen</a>
      </div>
      

      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar-content" aria-controls="navbar-content" aria-expanded="false" aria-label="Toggle navigation">
      <span><i class="fas fa-bars"></i></span>
      </button>
      

      
      <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
        <a class="navbar-brand" href="/">Yun Chen</a>
      </div>
      

      
      
      <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

        
        <ul class="navbar-nav d-md-inline-flex">
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#about" data-target="#about"><span>Home</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#projects" data-target="#projects"><span>Projects</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#featured" data-target="#featured"><span>Publications</span></a>
          </li>

          
          

          

          
          
          
            
              
            
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link " href="https://scholar.google.com/citations?hl=en&amp;user=y0aHCgkAAAAJ" target="_blank" rel="noopener"><span>Scholar</span></a>
          </li>

          
          

        

          
        </ul>
      </div>

      <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">

        
        
          
        

        
        
        
        <li class="nav-item">
          <a class="nav-link js-search" href="#" aria-label="Search"><i class="fas fa-search" aria-hidden="true"></i></a>
        </li>
        

        
        
        
        <li class="nav-item dropdown theme-dropdown">
          <a href="#" class="nav-link" data-toggle="dropdown" aria-haspopup="true" aria-label="Display preferences">
            <i class="fas fa-moon" aria-hidden="true"></i>
          </a>
          <div class="dropdown-menu">
            <a href="#" class="dropdown-item js-set-theme-light">
              <span>Light</span>
            </a>
            <a href="#" class="dropdown-item js-set-theme-dark">
              <span>Dark</span>
            </a>
            <a href="#" class="dropdown-item js-set-theme-auto">
              <span>Automatic</span>
            </a>
          </div>
        </li>
        

        
        

      </ul>

    </div>
  </nav>
</header>


  </div>

  <div class="page-body">
    
    
    

    


  









  
  

<span class="js-widget-page d-none"></span>





  
  
  
  




  






























































<section id="about" class="home-section wg-about  "  >
 <div class="home-section-bg " >
   
 </div>
  <div class="container">

  

    









  










<div class="row">
  <div class="col-12 col-lg-4">
    <div id="profile">

      
      
      <img class="avatar avatar-circle"
           width="270" height="270"
           src="/authors/admin/avatar_hu6361694207278647054.jpg" alt="Yun Chen">
      

      <div class="portrait-title">

        <h2>Yun Chen</h2>

        <h3>Researcher/PhD student</h3>

        
        <h3>
          <a href="https://waabi.ai/" target="_blank" rel="noopener">
          <span>Waabi.AI</span>
          </a>
        </h3>
        
      </div>

      <ul class="network-icon" aria-hidden="true">
        
        
        
        
          
        
        
        
        
        
        <li>
          <a href="mailto:i@yun.am"  aria-label="envelope">
            <i class="fas fa-envelope big-icon"></i>
          </a>
        </li>
        
        
        
        
        
        
        
        
          
        
        <li>
          <a href="https://scholar.google.com/citations?hl=en&amp;user=y0aHCgkAAAAJ" target="_blank" rel="noopener" aria-label="google-scholar">
            <i class="ai ai-google-scholar big-icon"></i>
          </a>
        </li>
        
        
        
        
          
        
        
        
        
        
          
        
        <li>
          <a href="https://github.com/chenyuntc" target="_blank" rel="noopener" aria-label="github">
            <i class="fab fa-github big-icon"></i>
          </a>
        </li>
        
        
        
        
        
        
        
        
          
        
        <li>
          <a href="/files/cv.pdf"  aria-label="cv">
            <i class="ai ai-cv big-icon"></i>
          </a>
        </li>
        
      </ul>

    </div>
  </div>
  <div class="col-12 col-lg-8">

    
    <h1>Biography</h1>

    <div class="article-style">
      <p>I am a CS PhD candidate at the University of Toronto advised by Prof. <a href="http://www.cs.toronto.edu/~urtasun/" target="_blank" rel="noopener">Raquel Urtasun</a>, and a Senior Researcher at <a href="https://waabi.ai" target="_blank" rel="noopener">waabi.ai</a>.</p>
<p>My research interests lie at the intersection of computer vision, neural rendering, and autonomous driving. I am passionate about finding simple, elegant solutions to challenging problems.</p>
<p>Beyond academia, I am an advocate of Unix philosophy, a Linux enthusiast, and the author of the bestselling <a href="https://github.com/chenyuntc/pytorch-book" target="_blank" rel="noopener">PyTorch book</a>.</p>
<!-- , having previously worked as a research scientist at Uber ATG R&D. -->
<!-- Throughout my research career, I have collaborated closely with distinguished researchers including [Ming Liang](https://scholar.google.com/citations?user=I5kGk98AAAAJ&hl=en), [Bin Yang](http://www.cs.toronto.edu/~byang/), [Shenlong Wang](https://shenlong.web.illinois.edu/), and [Wei-chiu Ma](https://www.cs.cornell.edu/~weichiu/). -->
<!-- My research contributions have established new state-of-the-art benchmarks across multiple domains, including autonomous driving, natural language processing, and computer vision.  -->
<!-- I actively serve as a reviewer for top-tier conferences and journals in the field, including CVPR, ICCV, ECCV, ICLR, NeurIPS, ICML, CoRL, ICRA, IROS, ACCV, WACV, TIP, TPAMI, and RA-L. -->
<!-- % I used to actively contribute to the open-source community. -->
<blockquote>
<p>There should be one &ndash; and preferably only one &ndash; obvious way to do it. Although that way may not be obvious at first.</p>
</blockquote>

    </div>

    <div class="row">

      
      <div class="col-md-5">
        <div class="section-subheading">Interests</div>
        <ul class="ul-interests mb-0">
          
          <li>Autonomous Driving</li>
          
          <li>Computer Vision</li>
          
          <li>Sensor Simulation</li>
          
          <li>Linux</li>
          
        </ul>
      </div>
      

      
      <div class="col-md-7">
        <div class="section-subheading">Education</div>
        <ul class="ul-edu fa-ul mb-0">
          
          <li>
            <i class="fa-li fas fa-graduation-cap"></i>
            <div class="description">
              <p class="course">PhD in Computer Science, 2021-Now</p>
              <p class="institution">University of Toronto</p>
            </div>
          </li>
          
          <li>
            <i class="fa-li fas fa-graduation-cap"></i>
            <div class="description">
              <p class="course">MSc in Communication Eng., 2016-2019</p>
              <p class="institution">Beijing University of Posts and Telecommunications</p>
            </div>
          </li>
          
          <li>
            <i class="fa-li fas fa-graduation-cap"></i>
            <div class="description">
              <p class="course">BSc in Communication Engineering, 2012-2016</p>
              <p class="institution">Beijing University of Posts and Telecommunications</p>
            </div>
          </li>
          
        </ul>
      </div>
      

    </div>
  </div>
</div>


  

  </div>
</section>


  






























































<section id="publications" class="home-section wg-collection  "  >
 <div class="home-section-bg " >
   
 </div>
  <div class="container">

  
    <div class="row  ">
    
      
        <div class="section-heading col-12 col-lg-4 mb-3 mb-lg-0 d-flex flex-column align-items-center align-items-lg-start">
          <h1 class="mb-0">Research Publications</h1>
          
        </div>
      
    
  

    










  








  
  





















  




<div class="col-12 col-lg-8">

  

  
    







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/publication/g3r/" >G3R: Gradient Guided Generalizable Reconstruction</a>
    </div>

    
    <a href="/publication/g3r/"  class="summary-link">
      <div class="article-style">
        [ECCV 2024]  Large scene reconstruction (&gt;300 HD images) within 90s <p style="color:red;"> <b> Spotlight talk at Wild3D workshop </b></p>
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      <a href="/authors/yun-chen/">Yun Chen</a></span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      <a href="/authors/jingkang-wang/">Jingkang Wang</a></span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      <a href="/authors/ze-yang/">Ze Yang</a></span>, <span >
      <a href="/authors/siva-manivasagam/">Siva Manivasagam</a></span>, <span >
      <a href="/authors/raquel-urtasun/">Raquel Urtasun</a></span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/pdf/2409.19405" target="_blank" rel="noopener">
  PDF
</a>







  
    
  



  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://research-assets.waabi.ai/g3r/g3r_poster.pdf" target="_blank" rel="noopener">
  Poster
</a>








  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://research-assets.waabi.ai/g3r/video.mp4" target="_blank" rel="noopener">
    <i class="fas fa-video mr-1"></i>Video</a>

  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://waabi.ai/g3r/" target="_blank" rel="noopener">
    Project page</a>


    </div>
    

  </div>
  <div class="ml-3">
    
    
      
      
      <a href="/publication/g3r/" >
        <img src="/publication/g3r/featured_hu9758487857655217571.webp" height="84" width="150"
            alt="G3R: Gradient Guided Generalizable Reconstruction" loading="lazy">
      </a>
    
  </div>
</div>

  
    







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/publication/neuras/" >Real-Time Neural Rasterization for Large Scenes</a>
    </div>

    
    <a href="/publication/neuras/"  class="summary-link">
      <div class="article-style">
        [ICCV2023]  Realistic and Real-time rendering for urban driving scenes(1080x1920 at 100+fps)
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      <a href="/authors/jeffrey-yunfan-liu/">Jeffrey Yunfan Liu</a></span>, <span >
      <a href="/authors/yun-chen/">Yun Chen</a></span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal mentorship"></i>, <span >
      <a href="/authors/ze-yang/">Ze Yang</a></span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal mentorship"></i>, <span >
      <a href="/authors/jingkang-wang/">Jingkang Wang</a></span>, <span >
      <a href="/authors/siva-manivasagam/">Siva Manivasagam</a></span>, <span >
      <a href="/authors/raquel-urtasun/">Raquel Urtasun</a></span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/pdf/2311.05607.pdf" target="_blank" rel="noopener">
  PDF
</a>







  
    
  



  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://research-assets.waabi.ai/NeuRas/poster_real-time.pdf" target="_blank" rel="noopener">
  Poster
</a>








  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://research-assets.waabi.ai/NeuRas/teaser.mp4" target="_blank" rel="noopener">
    <i class="fas fa-video mr-1"></i>Teaser Video</a>

  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://waabi.ai/neuras/" target="_blank" rel="noopener">
    Project page</a>


    </div>
    

  </div>
  <div class="ml-3">
    
    
      
      
      <a href="/publication/neuras/" >
        <img src="/publication/neuras/featured_hu8036195444236022580.gif" height="102" width="150"
            alt="Real-Time Neural Rasterization for Large Scenes" loading="lazy">
      </a>
    
  </div>
</div>

  
    







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/publication/unisim/" >UniSim: A Neural Closed-Loop Sensor Simulator</a>
    </div>

    
    <a href="/publication/unisim/"  class="summary-link">
      <div class="article-style">
        <p style="color:red;"> <b> CVPR 2023 Highlight</b></p> A realistic neural closed-Loop sensor simulator for camera and LiDAR
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      <a href="/authors/ze-yang/">Ze Yang</a></span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      <a href="/authors/yun-chen/">Yun Chen</a></span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      <a href="/authors/jingkang-wang/">Jingkang Wang</a></span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      <a href="/authors/siva-manivasagam/">Siva Manivasagam</a></span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      <a href="/authors/wei-chiu-ma/">Wei-Chiu Ma</a></span>, <span >
      <a href="/authors/anqi-joyce-yang/">Anqi Joyce Yang</a></span>, <span >
      <a href="/authors/raquel-urtasun/">Raquel Urtasun</a></span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/pdf/2308.01898.pdf" target="_blank" rel="noopener">
  PDF
</a>







  
    
  



  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://raw.githubusercontent.com/chenyuntc/CVPR2023-highlight-posters/main/posters/22272_UniSim-_A_Neural_Closed-Loop_Sensor_Simulator_poster.png" target="_blank" rel="noopener">
  Poster
</a>








  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://research-assets.waabi.ai/wp-content/uploads/2023/05/unisim_final_new_v2_1080p_compress_50m.mp4" target="_blank" rel="noopener">
    <i class="fas fa-video mr-1"></i>Teaser Video</a>

  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://waabi.ai/unisim/" target="_blank" rel="noopener">
    Project page</a>


    </div>
    

  </div>
  <div class="ml-3">
    
    
      
      
      <a href="/publication/unisim/" >
        <img src="/publication/unisim/featured_hu11433633729703997748.webp" height="90" width="150"
            alt="UniSim: A Neural Closed-Loop Sensor Simulator" loading="lazy">
      </a>
    
  </div>
</div>

  
    







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/publication/geosim/" >GeoSim: Realistic Video Simulation via Geometry-Aware Composition for Self-Driving</a>
    </div>

    
    <a href="/publication/geosim/"  class="summary-link">
      <div class="article-style">
        <p style="color:red;"> <b> CVPR 2021 Best Paper Candidate</b></p> A geometry-aware image composition process (GeoSim) that synthesizes novel urban driving scenes by augmenting existing images with dynamic objects extracted from other scenes and rendered at novel poses.
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      <a href="/authors/yun-chen/">Yun Chen</a></span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      <a href="/authors/frieda-rong/">Frieda Rong</a></span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      <a href="/authors/shivam-duggal/">Shivam Duggal</a></span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      <a href="/authors/shenlong-wang/">Shenlong Wang</a></span>, <span >
      <a href="/authors/xinchen-yan/">Xinchen Yan</a></span>, <span >
      <a href="/authors/sivabalan-manivasagam/">Sivabalan Manivasagam</a></span>, <span >
      <a href="/authors/shangjie-xue/">Shangjie Xue</a></span>, <span >
      <a href="/authors/ersin-yumer/">Ersin Yumer</a></span>, <span >
      <a href="/authors/raquel-urtasun/">Raquel Urtasun</a></span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/pdf/2101.06543" target="_blank" rel="noopener">
  PDF
</a>







  
    
  



  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="/publication/geosim/imgs/poster.pdf" target="_blank" rel="noopener">
  Poster
</a>








  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://youtu.be/_VLXc_VN0fE" target="_blank" rel="noopener">
    <i class="fab fa-youtube mr-1"></i>Youtube</a>

  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://yun.sfo2.digitaloceanspaces.com/public/geosim/geosim-4K.mp4" target="_blank" rel="noopener">
    <i class="fas fa-video mr-1"></i>4K Qualitative Results</a>


    </div>
    

  </div>
  <div class="ml-3">
    
    
      
      
      <a href="/publication/geosim/" >
        <img src="/publication/geosim/featured_hu3162013569414683912.gif" height="86" width="150"
            alt="GeoSim: Realistic Video Simulation via Geometry-Aware Composition for Self-Driving" loading="lazy">
      </a>
    
  </div>
</div>

  
    







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/publication/lanegcn/" >Learning Lane Graph Representations for Motion Forecasting</a>
    </div>

    
    <a href="/publication/lanegcn/"  class="summary-link">
      <div class="article-style">
        <p style="color:red;"> <b>ECCV 2020 Oral</b></p> We propose a motion forecasting model that exploits a novel structured map representation as well as actor-map …
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      <a href="/authors/ming-liang/">Ming Liang</a></span>, <span >
      <a href="/authors/bin-yang/">Bin Yang</a></span>, <span >
      <a href="/authors/rui-hu/">Rui Hu</a></span>, <span >
      <a href="/authors/yun-chen/">Yun Chen</a></span>, <span >
      <a href="/authors/renjie-liao/">Renjie Liao</a></span>, <span >
      <a href="/authors/song-feng/">Song Feng</a></span>, <span >
      <a href="/authors/raquel-urtasun/">Raquel Urtasun</a></span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="http://www.cs.toronto.edu/~byang/papers/mmf.pdf" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/lanegcn/cite.bib">
  Cite
</a>


  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/uber-research/lanegcn" target="_blank" rel="noopener">
  Code
</a>




  
    
  




  




<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://doi.org/10.1007/978-3-030-58536-5_32" target="_blank" rel="noopener">
  DOI
</a>


  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://evalai.cloudcv.org/web/challenges/challenge-page/454/leaderboard/1279" target="_blank" rel="noopener">
    SOTA in ArgoVerse</a>


    </div>
    

  </div>
  <div class="ml-3">
    
    
      
      
      <a href="/publication/lanegcn/" >
        <img src="/publication/lanegcn/featured_hu17993759389578867182.webp" height="47" width="150"
            alt="Learning Lane Graph Representations for Motion Forecasting" loading="lazy">
      </a>
    
  </div>
</div>

  

  
  
  

    
    
      
    

    
    
    
    
      
    

    

    <div class="see-all">
      <a href="/publication/">
        See all publications
        <i class="fas fa-angle-right"></i>
      </a>
    </div>
  

</div>


  
    </div>
  

  </div>
</section>


  




































  
  



























<section id="experience" class="home-section wg-experience  " style="padding: 20px 0 20px 0;" >
 <div class="home-section-bg " >
   
 </div>
  <div class="container">

  
    <div class="row  ">
    
      
        <div class="section-heading col-12 col-lg-4 mb-3 mb-lg-0 d-flex flex-column align-items-center align-items-lg-start">
          <h1 class="mb-0">Experience</h1>
          
        </div>
      
    
  

    









<div class="col-12 col-lg-8">
  

  
  

  
  
  <div class="row experience">
    
    <div class="col-auto text-center flex-column d-none d-sm-flex">
      <div class="row h-50">
        <div class="col ">&nbsp;</div>
        <div class="col">&nbsp;</div>
      </div>
      <div class="m-2">
        <span class="badge badge-pill border exp-fill">&nbsp;</span>
      </div>
      <div class="row h-50">
        <div class="col border-right">&nbsp;</div>
        <div class="col">&nbsp;</div>
      </div>
    </div>
    
    <div class="col py-2">
      <div class="card">
        <div class="card-body">

              <div class="section-subheading card-title exp-title text-muted my-0">Researcher</div>
              <div class="section-subheading card-title exp-company text-muted my-0"><a href="https://www.uber.com/ca/en/atg/research-and-development/" target="_blank" rel="noopener">Waabi AI</a></div>
              <div class="text-muted exp-meta">
                Jun 2021 –
                
                  Present
                
                
                  <span class="middot-divider"></span>
                  <span>Toronto, Canada</span>
                
              </div>

          <div class="card-text">Research focus on 3D reconstruction and sensor simulation, espeically Camera Simulation.</div>
        </div>
      </div>
    </div>
  </div>
  
  <div class="row experience">
    
    <div class="col-auto text-center flex-column d-none d-sm-flex">
      <div class="row h-50">
        <div class="col border-right">&nbsp;</div>
        <div class="col">&nbsp;</div>
      </div>
      <div class="m-2">
        <span class="badge badge-pill border exp-fill">&nbsp;</span>
      </div>
      <div class="row h-50">
        <div class="col border-right">&nbsp;</div>
        <div class="col">&nbsp;</div>
      </div>
    </div>
    
    <div class="col py-2">
      <div class="card">
        <div class="card-body">

              <div class="section-subheading card-title exp-title text-muted my-0">Research Scientist</div>
              <div class="section-subheading card-title exp-company text-muted my-0"><a href="https://www.uber.com/ca/en/atg/research-and-development/" target="_blank" rel="noopener">Uber ATG R&amp;D</a></div>
              <div class="text-muted exp-meta">
                Dec 2019 –
                
                  Present
                
                
                  <span class="middot-divider"></span>
                  <span>Toronto, Canada</span>
                
              </div>

          <div class="card-text"><p>Working closely with <a href="http://www.cs.toronto.edu/~urtasun/" target="_blank" rel="noopener">Prof. Raquel Urtasun</a> and <a href="http://www.cs.toronto.edu/~slwang/" target="_blank" rel="noopener">Prof. Shenlong Wang</a> on 3D simulation.</p>
<ul>
<li>3D Reconstruction with large-scale weakly-labelled data in the wild</li>
<li>Photorealistic Image Simulation with Geometry-Aware Composition for Self-Driving</li>
</ul></div>
        </div>
      </div>
    </div>
  </div>
  
  <div class="row experience">
    
    <div class="col-auto text-center flex-column d-none d-sm-flex">
      <div class="row h-50">
        <div class="col border-right">&nbsp;</div>
        <div class="col">&nbsp;</div>
      </div>
      <div class="m-2">
        <span class="badge badge-pill border ">&nbsp;</span>
      </div>
      <div class="row h-50">
        <div class="col border-right">&nbsp;</div>
        <div class="col">&nbsp;</div>
      </div>
    </div>
    
    <div class="col py-2">
      <div class="card">
        <div class="card-body">

              <div class="section-subheading card-title exp-title text-muted my-0">AI Resident</div>
              <div class="section-subheading card-title exp-company text-muted my-0"><a href="https://www.uber.com/ca/en/atg/research-and-development/" target="_blank" rel="noopener">Uber ATG R&amp;D</a></div>
              <div class="text-muted exp-meta">
                Sep 2018 –
                
                  Dec 2019
                
                
                  <span class="middot-divider"></span>
                  <span>Toronto, Canada</span>
                
              </div>

          <div class="card-text"><p>Working closely with <a href="https://scholar.google.com/citations?user=I5kGk98AAAAJ&amp;hl=en" target="_blank" rel="noopener">Ming Liang</a> and <a href="http://www.cs.toronto.edu/~byang/" target="_blank" rel="noopener">Bin Yang</a> in ATG R&amp;D for 3D Perception tasks.</p>
<ul>
<li>Depth Completion: Densify LiDAR with image guidance, SOTA in KITTI</li>
<li>3D Perception: 3D detection, tracking with multi-sensor. New SOTA in KITTI</li>
<li>Map structure learning with graph neural network. New SOTA in Argoverse motion forecasting</li>
</ul></div>
        </div>
      </div>
    </div>
  </div>
  
  <div class="row experience">
    
    <div class="col-auto text-center flex-column d-none d-sm-flex">
      <div class="row h-50">
        <div class="col border-right">&nbsp;</div>
        <div class="col">&nbsp;</div>
      </div>
      <div class="m-2">
        <span class="badge badge-pill border ">&nbsp;</span>
      </div>
      <div class="row h-50">
        <div class="col ">&nbsp;</div>
        <div class="col">&nbsp;</div>
      </div>
    </div>
    
    <div class="col py-2">
      <div class="card">
        <div class="card-body">

              <div class="section-subheading card-title exp-title text-muted my-0">Research Intern</div>
              <div class="section-subheading card-title exp-company text-muted my-0"><a href="https://damo.alibaba.com/labs/?goto=1" target="_blank" rel="noopener">Alibaba DAMO Academy</a></div>
              <div class="text-muted exp-meta">
                Mar 2018 –
                
                  Jul 2016
                
                
                  <span class="middot-divider"></span>
                  <span>Beijing, China</span>
                
              </div>

          <div class="card-text"><p>Working on Medical Imaging in Machine Intelligence Group led by <a href="https://scholar.google.com/citations?user=6G-l4o0AAAAJ&amp;hl=en" target="_blank" rel="noopener">Dr. Xian-Sheng Hua</a></p>
<ul>
<li>Developed 3D R-CNN for CT/MRI, faster and more accurate than radiologist.</li>
<li>Explored weakly-supervised learning with limited labels and active learning for efficient labelling.</li>
</ul></div>
        </div>
      </div>
    </div>
  </div>
  
  
</div>


  
    </div>
  

  </div>
</section>


  




































  
  



























<section id="projects" class="home-section wg-portfolio  " style="padding: 0px 0 10px 0;" >
 <div class="home-section-bg " >
   
 </div>
  <div class="container">

  
    <div class="row  ">
    
      
        <div class="section-heading col-12 col-lg-4 mb-3 mb-lg-0 d-flex flex-column align-items-center align-items-lg-start">
          <h1 class="mb-0">Projects</h1>
          
        </div>
      
    
  

    












<div class="col-12 col-lg-8">

  

  

    

    
    
    
    
      
      
        
      
    

    <span class="d-none default-project-filter">*</span>

    
    
  

  <div class="isotope projects-container js-layout-masonry ">

    
    

    
    
      
      
    
    
    
    
    
      
    

    
    
    
    
    

    
      
        
          <div class="project-card project-item isotope-item ">
        
        







  
  





  


<div class="card-simple view-card">

  
    


<div class="article-metadata">

  
  

  
  <span class="article-date">
    
    
      
    
    Apr 27, 2018
  </span>
  

  

  

  
  
  
  

  
  

</div>

  

  
  
  
    
    
    <a href="https://github.com/chenyuntc/simple-faster-rcnn-pytorch" target="_blank" rel="noopener">
      <div class="img-hover-zoom">
        <img src="/project/rcnn/featured_hu6619760562806584668.webp" height="455" width="808"
            class="article-banner" alt="Faster R-CNN" loading="lazy">
      </div>
    </a>
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="https://github.com/chenyuntc/simple-faster-rcnn-pytorch" target="_blank" rel="noopener">Faster R-CNN</a>
  </div>

  
  <a href="https://github.com/chenyuntc/simple-faster-rcnn-pytorch" target="_blank" rel="noopener" class="summary-link">
    <div class="article-style">
      <p>The <strong>FIRST</strong> pure PyTorch Faster R-CNN implementation, aiming at Simplicity and Readbility. Faster and Better.</p>
    </div>
  </a>
  

  

</div>

      </div>
    
      
        
          <div class="project-card project-item isotope-item ">
        
        







  
  





  


<div class="card-simple view-card">

  
    


<div class="article-metadata">

  
  

  
  <span class="article-date">
    
    
      
    
    Apr 27, 2018
  </span>
  

  

  

  
  
  
  

  
  

</div>

  

  
  
  
    
    
    <a href="https://github.com/chenyuntc/pytorch-book/blob/master/README_EN.md" target="_blank" rel="noopener">
      <div class="img-hover-zoom">
        <img src="/project/pytorch-book/featured_hu315019010197063255.webp" height="455" width="808"
            class="article-banner" alt="Technical Book" loading="lazy">
      </div>
    </a>
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="https://github.com/chenyuntc/pytorch-book/blob/master/README_EN.md" target="_blank" rel="noopener">Technical Book</a>
  </div>

  
  <a href="https://github.com/chenyuntc/pytorch-book/blob/master/README_EN.md" target="_blank" rel="noopener" class="summary-link">
    <div class="article-style">
      <p>PyTorch book with anime generation, neural style, image caption and so on.</p>
    </div>
  </a>
  

  

</div>

      </div>
    

  </div>
</div>


  
    </div>
  

  </div>
</section>


  






























































<section id="featured" class="home-section wg-collection  "  >
 <div class="home-section-bg " >
   
 </div>
  <div class="container">

  
    <div class="row  ">
    
      
        <div class="section-heading col-12 col-lg-4 mb-3 mb-lg-0 d-flex flex-column align-items-center align-items-lg-start">
          <h1 class="mb-0">Featured Publications</h1>
          
        </div>
      
    
  

    










  








  
  





















  




<div class="col-12 col-lg-8">

  

  
    











  


<div class="card-simple view-card">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span >
      <a href="/authors/yun-chen/">Yun Chen</a></span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      <a href="/authors/jingkang-wang/">Jingkang Wang</a></span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      <a href="/authors/ze-yang/">Ze Yang</a></span>, <span >
      <a href="/authors/siva-manivasagam/">Siva Manivasagam</a></span>, <span >
      <a href="/authors/raquel-urtasun/">Raquel Urtasun</a></span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    October, 2024
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      ECCV 2024
    
  </span>
  

  

  
  
  
  

  
  

</div>

  

  
  
  
    
    
    <a href="/publication/g3r/" >
      <div class="img-hover-zoom">
        <img src="/publication/g3r/featured_hu769910282788736142.webp" height="455" width="808"
            class="article-banner" alt="G3R: Gradient Guided Generalizable Reconstruction" loading="lazy">
      </div>
    </a>
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="/publication/g3r/" >G3R: Gradient Guided Generalizable Reconstruction</a>
  </div>

  
  <a href="/publication/g3r/"  class="summary-link">
    <div class="article-style">
      <p>[ECCV 2024]  Large scene reconstruction (&gt;300 HD images) within 90s <p style="color:red;"> <b> Spotlight talk at Wild3D workshop </b></p></p>
    </div>
  </a>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/pdf/2409.19405" target="_blank" rel="noopener">
  PDF
</a>







  
    
  



  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://research-assets.waabi.ai/g3r/g3r_poster.pdf" target="_blank" rel="noopener">
  Poster
</a>








  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://research-assets.waabi.ai/g3r/video.mp4" target="_blank" rel="noopener">
    <i class="fas fa-video mr-1"></i>Video</a>

  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://waabi.ai/g3r/" target="_blank" rel="noopener">
    Project page</a>


  </div>
  

</div>

  
    











  


<div class="card-simple view-card">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span >
      <a href="/authors/jeffrey-yunfan-liu/">Jeffrey Yunfan Liu</a></span>, <span >
      <a href="/authors/yun-chen/">Yun Chen</a></span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal mentorship"></i>, <span >
      <a href="/authors/ze-yang/">Ze Yang</a></span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal mentorship"></i>, <span >
      <a href="/authors/jingkang-wang/">Jingkang Wang</a></span>, <span >
      <a href="/authors/siva-manivasagam/">Siva Manivasagam</a></span>, <span >
      <a href="/authors/raquel-urtasun/">Raquel Urtasun</a></span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    October, 2023
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      ICCV 2023
    
  </span>
  

  

  
  
  
  

  
  

</div>

  

  
  
  
    
    
    <a href="/publication/neuras/" >
      <div class="img-hover-zoom">
        <img src="/publication/neuras/featured_hu2228652637934539106.gif" height="455" width="808"
            class="article-banner" alt="Real-Time Neural Rasterization for Large Scenes" loading="lazy">
      </div>
    </a>
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="/publication/neuras/" >Real-Time Neural Rasterization for Large Scenes</a>
  </div>

  
  <a href="/publication/neuras/"  class="summary-link">
    <div class="article-style">
      <p>[ICCV2023]  Realistic and Real-time rendering for urban driving scenes(1080x1920 at 100+fps)</p>
    </div>
  </a>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/pdf/2311.05607.pdf" target="_blank" rel="noopener">
  PDF
</a>







  
    
  



  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://research-assets.waabi.ai/NeuRas/poster_real-time.pdf" target="_blank" rel="noopener">
  Poster
</a>








  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://research-assets.waabi.ai/NeuRas/teaser.mp4" target="_blank" rel="noopener">
    <i class="fas fa-video mr-1"></i>Teaser Video</a>

  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://waabi.ai/neuras/" target="_blank" rel="noopener">
    Project page</a>


  </div>
  

</div>

  
    











  


<div class="card-simple view-card">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span >
      <a href="/authors/ze-yang/">Ze Yang</a></span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      <a href="/authors/yun-chen/">Yun Chen</a></span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      <a href="/authors/jingkang-wang/">Jingkang Wang</a></span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      <a href="/authors/siva-manivasagam/">Siva Manivasagam</a></span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      <a href="/authors/wei-chiu-ma/">Wei-Chiu Ma</a></span>, <span >
      <a href="/authors/anqi-joyce-yang/">Anqi Joyce Yang</a></span>, <span >
      <a href="/authors/raquel-urtasun/">Raquel Urtasun</a></span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    June, 2023
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
  </span>
  

  

  
  
  
  

  
  

</div>

  

  
  
  
    
    
    <a href="/publication/unisim/" >
      <div class="img-hover-zoom">
        <img src="/publication/unisim/featured_hu4543696476180381518.webp" height="455" width="808"
            class="article-banner" alt="UniSim: A Neural Closed-Loop Sensor Simulator" loading="lazy">
      </div>
    </a>
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="/publication/unisim/" >UniSim: A Neural Closed-Loop Sensor Simulator</a>
  </div>

  
  <a href="/publication/unisim/"  class="summary-link">
    <div class="article-style">
      <p><p style="color:red;"> <b> CVPR 2023 Highlight</b></p> A realistic neural closed-Loop sensor simulator for camera and LiDAR</p>
    </div>
  </a>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/pdf/2308.01898.pdf" target="_blank" rel="noopener">
  PDF
</a>







  
    
  



  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://raw.githubusercontent.com/chenyuntc/CVPR2023-highlight-posters/main/posters/22272_UniSim-_A_Neural_Closed-Loop_Sensor_Simulator_poster.png" target="_blank" rel="noopener">
  Poster
</a>








  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://research-assets.waabi.ai/wp-content/uploads/2023/05/unisim_final_new_v2_1080p_compress_50m.mp4" target="_blank" rel="noopener">
    <i class="fas fa-video mr-1"></i>Teaser Video</a>

  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://waabi.ai/unisim/" target="_blank" rel="noopener">
    Project page</a>


  </div>
  

</div>

  
    











  


<div class="card-simple view-card">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span >
      <a href="/authors/yun-chen/">Yun Chen</a></span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      <a href="/authors/frieda-rong/">Frieda Rong</a></span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      <a href="/authors/shivam-duggal/">Shivam Duggal</a></span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      <a href="/authors/shenlong-wang/">Shenlong Wang</a></span>, <span >
      <a href="/authors/xinchen-yan/">Xinchen Yan</a></span>, <span >
      <a href="/authors/sivabalan-manivasagam/">Sivabalan Manivasagam</a></span>, <span >
      <a href="/authors/shangjie-xue/">Shangjie Xue</a></span>, <span >
      <a href="/authors/ersin-yumer/">Ersin Yumer</a></span>, <span >
      <a href="/authors/raquel-urtasun/">Raquel Urtasun</a></span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    June, 2021
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
  </span>
  

  

  
  
  
  

  
  

</div>

  

  
  
  
    
    
    <a href="/publication/geosim/" >
      <div class="img-hover-zoom">
        <img src="/publication/geosim/featured_hu5978768746836318891.gif" height="455" width="808"
            class="article-banner" alt="GeoSim: Realistic Video Simulation via Geometry-Aware Composition for Self-Driving" loading="lazy">
      </div>
    </a>
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="/publication/geosim/" >GeoSim: Realistic Video Simulation via Geometry-Aware Composition for Self-Driving</a>
  </div>

  
  <a href="/publication/geosim/"  class="summary-link">
    <div class="article-style">
      <p><p style="color:red;"> <b> CVPR 2021 Best Paper Candidate</b></p> A geometry-aware image composition process (GeoSim) that synthesizes novel urban driving scenes by augmenting existing images with dynamic objects extracted from other scenes and rendered at novel poses.</p>
    </div>
  </a>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/pdf/2101.06543" target="_blank" rel="noopener">
  PDF
</a>







  
    
  



  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="/publication/geosim/imgs/poster.pdf" target="_blank" rel="noopener">
  Poster
</a>








  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://youtu.be/_VLXc_VN0fE" target="_blank" rel="noopener">
    <i class="fab fa-youtube mr-1"></i>Youtube</a>

  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://yun.sfo2.digitaloceanspaces.com/public/geosim/geosim-4K.mp4" target="_blank" rel="noopener">
    <i class="fas fa-video mr-1"></i>4K Qualitative Results</a>


  </div>
  

</div>

  
    











  


<div class="card-simple view-card">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span >
      <a href="/authors/ming-liang/">Ming Liang</a></span>, <span >
      <a href="/authors/bin-yang/">Bin Yang</a></span>, <span >
      <a href="/authors/rui-hu/">Rui Hu</a></span>, <span >
      <a href="/authors/yun-chen/">Yun Chen</a></span>, <span >
      <a href="/authors/renjie-liao/">Renjie Liao</a></span>, <span >
      <a href="/authors/song-feng/">Song Feng</a></span>, <span >
      <a href="/authors/raquel-urtasun/">Raquel Urtasun</a></span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    September, 2020
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In <em>ECCV 2020</em>
    
  </span>
  

  

  
  
  
  

  
  

</div>

  

  
  
  
    
    
    <a href="/publication/lanegcn/" >
      <div class="img-hover-zoom">
        <img src="/publication/lanegcn/featured_hu13974835076606607346.webp" height="455" width="808"
            class="article-banner" alt="Learning Lane Graph Representations for Motion Forecasting" loading="lazy">
      </div>
    </a>
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="/publication/lanegcn/" >Learning Lane Graph Representations for Motion Forecasting</a>
  </div>

  
  <a href="/publication/lanegcn/"  class="summary-link">
    <div class="article-style">
      <p><p style="color:red;"> <b>ECCV 2020 Oral</b></p> We propose a motion forecasting model that exploits a novel structured map representation as well as actor-map interactions. Instead of encoding vectorized maps as raster images, we construct a lane graph from raw map data to explicitly preserve the map structure. To capture the complex topology and long range dependencies of the lane graph, we propose LaneGCN which extends graph convolutions with multiple adjacency matrices and along-lane dilation. To capture the complex interactions between actors and maps, we exploit a fusion network consisting of four types of interactions, actor-to-lane, lane-to-lane, laneto-actor and actor-to-actor. Powered by LaneGCN and actor-map interactions, our model is able to predict accurate and realistic multi-modal trajectories. Our approach significantly outperforms the state-of-the-art on the large scale Argoverse motion forecasting benchmark.</p>
    </div>
  </a>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="http://www.cs.toronto.edu/~byang/papers/mmf.pdf" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/lanegcn/cite.bib">
  Cite
</a>


  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/uber-research/lanegcn" target="_blank" rel="noopener">
  Code
</a>




  
    
  




  




<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://doi.org/10.1007/978-3-030-58536-5_32" target="_blank" rel="noopener">
  DOI
</a>


  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://evalai.cloudcv.org/web/challenges/challenge-page/454/leaderboard/1279" target="_blank" rel="noopener">
    SOTA in ArgoVerse</a>


  </div>
  

</div>

  
    











  


<div class="card-simple view-card">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span >
      <a href="/authors/wenyuan-zeng/">Wenyuan Zeng</a></span>, <span >
      <a href="/authors/shenlong-wang/">Shenlong Wang</a></span>, <span >
      <a href="/authors/renjie-liao/">Renjie Liao</a></span>, <span >
      <a href="/authors/yun-chen/">Yun Chen</a></span>, <span >
      <a href="/authors/bin-yang/">Bin Yang</a></span>, <span >
      <a href="/authors/raquel-urtasun/">Raquel Urtasun</a></span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    September, 2020
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In <em>ECCV 2020</em>
    
  </span>
  

  

  
  
  
  

  
  

</div>

  

  
  
  
    
    
    <a href="/publication/dsdnet/" >
      <div class="img-hover-zoom">
        <img src="/publication/dsdnet/featured_hu7881346586830583505.webp" height="455" width="808"
            class="article-banner" alt="Dsdnet: Deep structured self-driving network" loading="lazy">
      </div>
    </a>
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="/publication/dsdnet/" >Dsdnet: Deep structured self-driving network</a>
  </div>

  
  <a href="/publication/dsdnet/"  class="summary-link">
    <div class="article-style">
      <p>[ECCV 2020] In this paper, we propose the Deep Structured self-Driving Network (DSDNet), which performs object detection, motion prediction, and motion planning with a single neural network. Towards this goal, we develop a deep structured energy based model which considers the interactions between actors and produces socially consistent multimodal future predictions. Furthermore, DSDNet explicitly exploits the predicted future distributions of actors to plan a safe maneuver by using a structured planning cost. Our sample-based formulation allows us to overcome the difficulty in probabilistic inference of continuous random variables. Experiments on a number of large-scale self driving datasets demonstrate that our model significantly outperforms the state-of-the-art.</p>
    </div>
  </a>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/pdf/2008.06041" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/dsdnet/cite.bib">
  Cite
</a>





  
    
  




  




<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://doi.org/10.1007/978-3-030-58589-1_10" target="_blank" rel="noopener">
  DOI
</a>



  </div>
  

</div>

  
    











  


<div class="card-simple view-card">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span >
      <a href="/authors/ming-liang/">Ming Liang</a></span>, <span >
      <a href="/authors/bin-yang/">Bin Yang</a></span>, <span >
      <a href="/authors/wenyuan-zeng/">Wenyuan Zeng</a></span>, <span >
      <a href="/authors/yun-chen/">Yun Chen</a></span>, <span >
      <a href="/authors/rui-hu/">Rui Hu</a></span>, <span >
      <a href="/authors/sergio-casas/">Sergio Casas</a></span>, <span >
      <a href="/authors/raquel-urtasun/">Raquel Urtasun</a></span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    June, 2020
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In <em>CVPR 2020</em>
    
  </span>
  

  

  
  
  
  

  
  

</div>

  

  
  
  
    
    
    <a href="/publication/pnpnet/" >
      <div class="img-hover-zoom">
        <img src="/publication/pnpnet/featured_hu10959251019423062315.webp" height="455" width="808"
            class="article-banner" alt="PnPNet: End-to-End Perception and Prediction with Tracking in the Loop" loading="lazy">
      </div>
    </a>
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="/publication/pnpnet/" >PnPNet: End-to-End Perception and Prediction with Tracking in the Loop</a>
  </div>

  
  <a href="/publication/pnpnet/"  class="summary-link">
    <div class="article-style">
      <p>[CVPR 2020]We tackle the problem of joint perception and motion forecasting in the context of self-driving vehicles. Towards this goal we propose PnPNet, an end-to-end model that takes as input sequential sensor data, and outputs at each time step object tracks and their future trajectories. The key component is a novel tracking module that generates object tracks online from detections and exploits trajectory level features for motion forecasting. Specifically, the object tracks get updated at each time step by solving both the data association problem and the trajectory estimation problem. Importantly, the whole model is end-to-end trainable and benefits from joint optimization of all tasks. We validate PnPNet on two large-scale driving datasets, and show significant improvements over the state-of-the-art with better occlusion recovery and more accurate future prediction.</p>
    </div>
  </a>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="http://openaccess.thecvf.com/content_CVPR_2020/papers/Liang_PnPNet_End-to-End_Perception_and_Prediction_With_Tracking_in_the_Loop_CVPR_2020_paper.pdf" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/pnpnet/cite.bib">
  Cite
</a>





  
    
  




  




<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://doi.org/10.1109/CVPR42600.2020.01157" target="_blank" rel="noopener">
  DOI
</a>



  </div>
  

</div>

  
    











  


<div class="card-simple view-card">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span >
      <a href="/authors/yun-chen/">Yun Chen</a></span>, <span >
      <a href="/authors/bin-yang/">Bin Yang</a></span>, <span >
      <a href="/authors/ming-liang/">Ming Liang</a></span>, <span >
      <a href="/authors/raquel-urtasun/">Raquel Urtasun</a></span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    October, 2019
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In <em>ICCV 2019</em>
    
  </span>
  

  

  
  
  
  

  
  

</div>

  

  
  
  
    
    
    <a href="/publication/fusenet/" >
      <div class="img-hover-zoom">
        <img src="/publication/fusenet/featured_hu15600675357155944925.webp" height="455" width="808"
            class="article-banner" alt="Learning Joint 2D-3D Representations for Depth Completion" loading="lazy">
      </div>
    </a>
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="/publication/fusenet/" >Learning Joint 2D-3D Representations for Depth Completion</a>
  </div>

  
  <a href="/publication/fusenet/"  class="summary-link">
    <div class="article-style">
      <p>[ICCV 2019] Depth completion using 2D-3D fusion. New SOTA achieved in KITTI.</p>
    </div>
  </a>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="/publication/fusenet/depth_completion_iccv2019_chen.pdf" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/fusenet/cite.bib">
  Cite
</a>





  
    
  



  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="/publication/fusenet/iccv2019-fusenet-poster.pdf" target="_blank" rel="noopener">
  Poster
</a>


  




<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://doi.org/10.1109/ICCV.2019.01012" target="_blank" rel="noopener">
  DOI
</a>


  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="http://www.cvlibs.net/datasets/kitti/eval_depth.php?benchmark=depth_completion" target="_blank" rel="noopener">
    SOTA on KITTI</a>


  </div>
  

</div>

  
    











  


<div class="card-simple view-card">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span >
      <a href="/authors/ming-liang/">Ming Liang</a></span>, <span >
      <a href="/authors/bin-yang/">Bin Yang</a></span>, <span >
      <a href="/authors/yun-chen/">Yun Chen</a></span>, <span >
      <a href="/authors/rui-hu/">Rui Hu</a></span>, <span >
      <a href="/authors/raquel-urtasun/">Raquel Urtasun</a></span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    June, 2019
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In <em>CVPR 2019</em>
    
  </span>
  

  

  
  
  
  

  
  

</div>

  

  
  
  
    
    
    <a href="/publication/mmf/" >
      <div class="img-hover-zoom">
        <img src="/publication/mmf/featured_hu8989658176208289243.webp" height="455" width="808"
            class="article-banner" alt="Multi-task multi-sensor fusion for 3d object detection" loading="lazy">
      </div>
    </a>
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="/publication/mmf/" >Multi-task multi-sensor fusion for 3d object detection</a>
  </div>

  
  <a href="/publication/mmf/"  class="summary-link">
    <div class="article-style">
      <p>[CVPR 2019] In this paper we propose to exploit multiple related tasks for accurate multi-sensor 3D object detection. Towards this  goal we present an end-to-end learnable architecture that reasons about 2D and 3D object detection as well as ground estimation and depth completion. Our experiments show that all these tasks are complementary and help the network learn better representations by fusing information at various levels. Importantly, our approach leads the KITTI benchmark on 2D, 3D and bird’s eye view object detection, while being real-time</p>
    </div>
  </a>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="http://www.cs.toronto.edu/~byang/papers/mmf.pdf" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/mmf/cite.bib">
  Cite
</a>





  
    
  




  




<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://doi.org/10.1109/CVPR.2019.00752" target="_blank" rel="noopener">
  DOI
</a>


  
  
  
    
  
  
  
  
  
    
    
      
    
  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="/" >
    SOTA in KITTI</a>


  </div>
  

</div>

  
    











  


<div class="card-simple view-card">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span >
      <a href="/authors/yun-chen/">Yun Chen</a></span>, <span >
      <a href="/authors/junxuan-chen/">Junxuan Chen</a></span>, <span >
      <a href="/authors/bo-xiao/">Bo Xiao</a></span>, <span >
      <a href="/authors/zhengfang-wu/">Zhengfang Wu</a></span>, <span >
      <a href="/authors/ying-chi/">Ying Chi</a></span>, <span >
      <a href="/authors/xuansong-xie/">Xuansong Xie</a></span>, <span >
      <a href="/authors/xiansheng-hua/">Xiansheng Hua</a></span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    March, 2019
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In <em>ISBI 2019</em>
    
  </span>
  

  

  
  
  
  

  
  

</div>

  

  
  
  
    
    
    <a href="/publication/vrcnn/" >
      <div class="img-hover-zoom">
        <img src="/publication/vrcnn/featured_hu16242583901112786998.webp" height="455" width="808"
            class="article-banner" alt="Volume R-CNN: Unified Framework for CT Object Detection and Instance Segmentation" loading="lazy">
      </div>
    </a>
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="/publication/vrcnn/" >Volume R-CNN: Unified Framework for CT Object Detection and Instance Segmentation</a>
  </div>

  
  <a href="/publication/vrcnn/"  class="summary-link">
    <div class="article-style">
      <p>[ISBI 2019] Accurate and Efficient 3D Nodule detection with 3D R-CNN.</p>
    </div>
  </a>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="/publication/vrcnn/isbi2019.pdf" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/vrcnn/cite.bib">
  Cite
</a>













<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://doi.org/10.1109/ISBI.2019.8759390" target="_blank" rel="noopener">
  DOI
</a>


  
  
  
    
  
  
  
  
  
    
    
      
    
  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="/publication/vrcnn/full.pdf" >
    Full-Version</a>


  </div>
  

</div>

  

  
  
  

</div>


  
    </div>
  

  </div>
</section>




  </div>

  <div class="page-footer">
    
    
    <div class="container">
      
    </div>
    
  </div>

  


<script src="/js/vendor-bundle.min.50933d940896e49f984a778650d5f7f5.js"></script>




  
    <script src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/gh/metafizzy/isotope@v3.0.6/dist/isotope.pkgd.min.js" integrity="sha512-Zq2BOxyhvnRFXu0+WE6ojpZLOU2jdnqbrM1hmVdGzyeCa1DgM3X5Q4A/Is9xA1IkbUeDd7755dNNI/PzSf2Pew==" crossorigin="anonymous"></script>
  

  
  

  






  <script src="https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.js" integrity="" crossorigin="anonymous"></script>








  
  <script id="search-hit-fuse-template" type="text/x-template">
    <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
    </div>
  </script>
  
    <script src="https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js" integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js" integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin="anonymous"></script>
  












  
  
  
  
  
  
  

















<script id="page-data" type="application/json">{"use_headroom":false}</script>











  
  


<script src="/en/js/wowchemy.min.7f5ebaff62ae468cff8bb3dd1337bb9b.js"></script>



  <script src="/js/wowchemy-map.a26e9d2f7238ba5b868384f1c5bc6477.js" type="module"></script>




  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        
        <pre><code></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>


  <script src="/js/wowchemy-publication.9c0e895144aef5a693008b5c5d450147.js" type="module"></script>


















</body>
</html>
