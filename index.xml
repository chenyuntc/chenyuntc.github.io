<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Yun Chen</title>
    <link>https://tmux.top/</link>
      <atom:link href="https://tmux.top/index.xml" rel="self" type="application/rss+xml" />
    <description>Yun Chen</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Sun, 01 Nov 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://tmux.top/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title>Yun Chen</title>
      <link>https://tmux.top/</link>
    </image>
    
    <item>
      <title>GeoSim: Realistic Video Simulation via Geometry-Aware Composition for Self-Driving</title>
      <link>https://tmux.top/publication/geosim/</link>
      <pubDate>Sun, 01 Nov 2020 00:00:00 +0000</pubDate>
      <guid>https://tmux.top/publication/geosim/</guid>
      <description>
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/FVUPX5MTSvs&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;In this paper, we present GeoSim, a geometry-aware image composition process which synthesizes novel urban driving scenarios by augmenting existing images with dynamic objects extracted from other scenes and rendered at novel poses. Towards this goal, we first build a diverse bank of 3D objects with both realistic geometry and appearance from sensor data. During simulation, we perform a novel geometry-aware simulation-by-composition procedure which 1) proposes plausible and realistic object placements into a given scene, 2) render novel views of dynamic objects from the asset bank, and 3) composes and blends the rendered image segments. The resulting synthetic images are realistic, traffic-aware, and geometrically consistent, allowing our approach to scale to complex use cases. We demonstrate two such important applications long-range realistic video simulation across multiple camera sensors, and synthetic data generation for data augmentation on downstream segmentation tasks.&lt;/p&gt;
&lt;p&gt;





  



  
  











&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://tmux.top/publication/geosim/featured_hu88deca36fbb348d956643be7ec6aac53_906310_2000x2000_fit_lanczos.gif&#34; &gt;


  &lt;img data-src=&#34;https://tmux.top/publication/geosim/featured_hu88deca36fbb348d956643be7ec6aac53_906310_2000x2000_fit_lanczos.gif&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;1824&#34; height=&#34;944&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
.&lt;/p&gt;
&lt;!-- 


&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;




&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Slides&lt;/em&gt; button above to demo Academic&amp;rsquo;s Markdown slides feature.
  &lt;/div&gt;
&lt;/div&gt;



Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/). --&gt;
</description>
    </item>
    
    <item>
      <title>Learning Lane Graph Representations for Motion Forecasting</title>
      <link>https://tmux.top/publication/lanegcn/</link>
      <pubDate>Wed, 02 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://tmux.top/publication/lanegcn/</guid>
      <description>&lt;!-- 


&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;




&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Slides&lt;/em&gt; button above to demo Academic&amp;rsquo;s Markdown slides feature.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/). --&gt;
</description>
    </item>
    
    <item>
      <title>Dsdnet: Deep structured self-driving network</title>
      <link>https://tmux.top/publication/dsdnet/</link>
      <pubDate>Tue, 01 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://tmux.top/publication/dsdnet/</guid>
      <description>&lt;!-- 


&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;




&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Slides&lt;/em&gt; button above to demo Academic&amp;rsquo;s Markdown slides feature.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/). --&gt;
</description>
    </item>
    
    <item>
      <title>PnPNet: End-to-End Perception and Prediction with Tracking in the Loop</title>
      <link>https://tmux.top/publication/pnpnet/</link>
      <pubDate>Mon, 01 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://tmux.top/publication/pnpnet/</guid>
      <description>&lt;!-- 


&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;




&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Slides&lt;/em&gt; button above to demo Academic&amp;rsquo;s Markdown slides feature.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/). --&gt;
</description>
    </item>
    
    <item>
      <title>Learning Joint 2D-3D Representations for Depth Completion</title>
      <link>https://tmux.top/publication/fusenet/</link>
      <pubDate>Tue, 01 Oct 2019 00:00:00 +0000</pubDate>
      <guid>https://tmux.top/publication/fusenet/</guid>
      <description>&lt;!-- 


&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;




&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Slides&lt;/em&gt; button above to demo Academic&amp;rsquo;s Markdown slides feature.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/). --&gt;
</description>
    </item>
    
    <item>
      <title>Multi-task multi-sensor fusion for 3d object detection</title>
      <link>https://tmux.top/publication/mmf/</link>
      <pubDate>Sat, 01 Jun 2019 00:00:00 +0000</pubDate>
      <guid>https://tmux.top/publication/mmf/</guid>
      <description>&lt;!-- 


&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;




&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Slides&lt;/em&gt; button above to demo Academic&amp;rsquo;s Markdown slides feature.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/). --&gt;
</description>
    </item>
    
    <item>
      <title>Volume R-CNN: Unified Framework for CT Object Detection and Instance Segmentation</title>
      <link>https://tmux.top/publication/vrcnn/</link>
      <pubDate>Fri, 01 Mar 2019 00:00:00 +0000</pubDate>
      <guid>https://tmux.top/publication/vrcnn/</guid>
      <description>&lt;h1 id=&#34;heading&#34;&gt;&lt;/h1&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    &lt;h1 id=&#34;click-the-cite-button-above-to-demo-the-feature-to-enable-visitors-to-import-publication-metadata-into-their-reference-management-software&#34;&gt;Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.&lt;/h1&gt;
&lt;h1 id=&#34;heading&#34;&gt;&lt;/h1&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;h1 id=&#34;heading-1&#34;&gt;&lt;/h1&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    &lt;h1 id=&#34;click-the-slides-button-above-to-demo-academics-markdown-slides-feature&#34;&gt;Click the &lt;em&gt;Slides&lt;/em&gt; button above to demo Academic&amp;rsquo;s Markdown slides feature.&lt;/h1&gt;
&lt;h1 id=&#34;heading&#34;&gt;&lt;/h1&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;h1 id=&#34;supplementary-notes-can-be-added-here-including-code-and-mathhttpssourcethemescomacademicdocswriting-markdown-latex&#34;&gt;Supplementary notes can be added here, including &lt;a href=&#34;https://sourcethemes.com/academic/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;code and math&lt;/a&gt;.&lt;/h1&gt;
</description>
    </item>
    
    <item>
      <title>Faster R-CNN</title>
      <link>https://tmux.top/project/rcnn/</link>
      <pubDate>Fri, 27 Apr 2018 00:00:00 +0000</pubDate>
      <guid>https://tmux.top/project/rcnn/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Technical Book</title>
      <link>https://tmux.top/project/pytorch-book/</link>
      <pubDate>Fri, 27 Apr 2018 00:00:00 +0000</pubDate>
      <guid>https://tmux.top/project/pytorch-book/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Projects on 3D Vision.</title>
      <link>https://tmux.top/post/summary/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://tmux.top/post/summary/</guid>
      <description>&lt;p&gt;Here is a summary of my projects on 3D vision.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Camera Simulation&lt;/strong&gt; for self-driving: Combine 3D reconstruction, image-based rendering and depth completion to create photo-realistic and geometrically consistent videos  (Under Review)&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://yun.sfo2.digitaloceanspaces.com/public/geosim-arxiv.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;[PDF]&lt;/a&gt; &lt;a href=&#34;https://x.i3c.xyz/public/geosim.mp4&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;[Video (4K Resolution)]&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;http://x.i3c.xyz/tmp/a.gif&#34; alt=&#34;Geosim Teaser&#34;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Depth Completion&lt;/strong&gt; by joint-learning of appearance feature and geometry feature. (ICCV 2019)&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://openaccess.thecvf.com/content_ICCV_2019/papers/Chen_Learning_Joint_2D-3D_Representations_for_Depth_Completion_ICCV_2019_paper.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;[PDF]&lt;/a&gt;  &lt;a href=&#34;http://x.i3c.xyz/public/depth_qual.mp4&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;[Qualitative Video]&lt;/a&gt; [&lt;a href=&#34;https://tmux.top/publication/fusenet/iccv2019-fusenet-poster.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Poster&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;http://yun.sfo2.digitaloceanspaces.com/cloud/homepage/image-20201219153358788.png&#34; alt=&#34;Featured&#34;&gt;&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Texture Reconstruction&lt;/strong&gt; in the wild [WIP]&lt;/p&gt;
&lt;p&gt;Self-supervised texture reconstruction with symmetry, inpainting and differential-rendering.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;http://yun.sfo2.digitaloceanspaces.com/cloud/homepage/tex_rec.gif&#34; alt=&#34;tex_rec&#34;&gt;&lt;/p&gt;
&lt;p&gt;Please contact me if you want to talk in more detail.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
